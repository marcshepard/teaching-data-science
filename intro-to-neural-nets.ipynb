{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is a motivational introduction to artificial neural networks (aka <i>neural nets</i>). We'll explore what they are, why they were created, how they work, and finally we'll create one that can recongize hand-written digits with a very high degree of accuracy.\n",
    "\n",
    "First let's talk about why neural nets were created in the first place. Prior to neural nets, computers could easily outperform people at tasks such as arithmatic, but were unable to do a decent job at many tasks that people found easy such as image recognition and natural language processing. As a simple example, consider the following set of images of hand-written digits:\n",
    "<center><img src=\"images/MNIST-digits.jpg\"/></center>\n",
    "\n",
    "Each one of the images above is a 25x25 grid of light intensities. Each element in the grid is called a <i>pixel</i>, which is short for picture element. Imagine trying to write a computer program to figure out what digit each picture represents; \"if pixel at location (2,3) > minimum_intensity and ... then output 1\" (or some such). It would be impossible, right?\n",
    "\n",
    "And the problem can be even harder for more complex images:\n",
    "<center><img src=\"images/Chihuahua-or-muffin.jpg\"/></center>\n",
    "\n",
    "To solve these problems, people came up with the idea of creating computer programs that work more like a brain; instead of creating code that is specific to a given problem, they create code that models a simple brain. They then train that brain by showing it data so it learns a specific task (like reconginizing hand-written digits, or distinguishing a chihuahua from a muffin); similar to how people learn. Let's look at how this works in more detail.\n",
    "\n",
    "# Artificial Neural Networks\n",
    "\n",
    "Per the picture below, each neuron in your brain takes inputs to it's <i>dendtrites</i> and, if the input signals are high enough, fires an output to it's <i>axon</i>.\n",
    "<center><img src=\"images/Neuron.jpg\"/></center>\n",
    "\n",
    "The human brain is made up of about 100 billion interconnected neurons, each with about 1000 connections to other neurons, for about 100 trillion neural connections! The connection between one neurons output axon and another neurons input dentrite is called a <i>synaptic connection</i>. All of your memories and knowledge and skills are encoding in the stength of the synaptic connections between your neurons. Learning is just the brain creating, strengthening, or weakening the 100 trillion synaptic connections between your neurons.\n",
    "\n",
    "Pictured below is an artificial neuron, which is modeled as a set of inputs (corresponding to dentrites), a set of weights to apply to each input (corresponding to synaptic stengths), and an output (corresponding to the axon). The artificial neurons weights can be adjusted to allow it to <i>learn</i>:\n",
    "<center><img src=\"images/Artificial-neuron.jpg\"/></center>\n",
    "\n",
    "Here's a quick summary of some of the key differences between the human brain and artificial neural networks:\n",
    "<table>\n",
    "<tr>\n",
    " <th/>\n",
    " <th>Human Brain</th>\n",
    " <th>Artificial</th>\n",
    "</tr>\n",
    "<tr>\n",
    " <td>Size</td>\n",
    " <td>100 trillion synaptic connections</td>\n",
    " <td>200 billion parameters for a very large network like ChatGPT, although small neural nets like we'll build may have just a few hundred neurons.</td>\n",
    "</tr>\n",
    "<tr>\n",
    " <td>Speed</td>\n",
    " <td>Hundreds of operations per second</td>\n",
    " <td>Billions of operations per second</td>\n",
    "</tr>\n",
    "<tr>\n",
    " <td>Parallelism</td>\n",
    " <td>All signals run in parallel</td>\n",
    " <td>CPUs can only a very small number of operations at a time. High end GPUs can run millions of operations to run at a time, but only if all the operations are the same</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "On a creepy note, researchers have also experimented with creating <a href=\"https://research.ufl.edu/publications/explore/v10n1/extract2.html\">neural nets from rat brains</a> and, after a number of studies, discovered that the rats don't like these experiments. For more information, please read <a href='https://towardsdatascience.com/the-differences-between-artificial-and-biological-neural-networks-a8b46db828b7'>artifical vs biological neural networks</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a Google Colab account\n",
    "In order to try things out yourself, you will first need to create a [Google colab](https://colab.research.google.com) account if you don't already have one. Colab was specifically built for creating and sharing interactive python data science code, and it's free tier is quite feature rich.\n",
    "\n",
    "From that account, Clone this notebook like so:\n",
    "1. Go to \"Open Notebook\" (it should have popped up by default, but if not you can find it under the \"File\" menu)\n",
    "2. Select \"GitHub\"\n",
    "3. Enter the following path: https://github.com/marcshepard/teaching-data-science/blob/main/openai.ipynb\n",
    "4. Click the search icon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducting the MNIST data set and TensorFlow\n",
    "\n",
    "We'll train a neural network to recognize hand-written digits. To do that, we'll need::\n",
    "1) A framework for creating neural networks. We'll use TensorFlow, created by Google (Meta's PyTorch is another popular framework, but is a bit more complicated).\n",
    "2) A dataset of labeled images of digits. By a labeled image, we mean both the image (a 28x28 grid of pixels) and the label (the actual number that was drawn in the image; 0, 1, ..., 9). We'll use the MNIST dataset, which contains a large set of labeled images for training the neural net, and another set of labeled images to test how the neural net performs on images it has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code cell (and later the ones below) using the icon to the left of the cell, or by pressing Shift+Enter\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train, test = tf.keras.datasets.mnist.load_data()   # Load the MNIST dataset\n",
    "train_images, train_labels = train                  # Put the training images and labels in separate variables\n",
    "\n",
    "# Normalize the images\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "# Show the first 20 images and their corresponding labels\n",
    "plt.figure(figsize=(10,10)) # Make is larger (10x10 inches) so you can see the pixels better\n",
    "for i in range(20):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(train_images[i], cmap='gray_r')      # Show the image in reverse grayscale\n",
    "    plt.xlabel(train_labels[i])                     # Show the label underneath the image\n",
    "# Add text to the top of the figure saying it's the first 20 images\n",
    "plt.suptitle(f\"The MNIST training data consists of {train_images.shape[0]} images, each of size {train_images.shape[1:]}.\\nHere are the first 20:\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple 3-layer neural net for processing the images:\n",
    "<center><img src=\"images/3-layer-net.jpg\"/></center>\n",
    "\n",
    "We'll use the following three layers:\n",
    "1) Input: Takes a 2d 28x28 image (28x28 grid of light intensitities) and flattens it to a 1-dimensional vector of 784 light intensities (784 = 28x28)\n",
    "2) Hidden: Takes 784 inputs from the previous layer and creates 16 outputs (so it has 16 'neurons', each getting full input from the previous layer) \n",
    "3) Output: Takes the 16 inputs and outputs 10 probabilities; the percent chance the network assigns to the image being each of the 10 possible digits)\n",
    "\n",
    "Let's create this neural network and see how well it does at recognizing the images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28), name=\"Input\"),    # Flatten the 28x28 images to a 1D array of 784 pixels\n",
    "    tf.keras.layers.Dense(16, activation='relu, name=\"Hidden\"'),    # Does some calculations across input pixels\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name=\"Output\")  # Predicts a probability for each digit\n",
    "])\n",
    "neural_net.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def show_predictions (images, labels, model):\n",
    "    predictions = model.predict(images) # Predict the labels for each images\n",
    "\n",
    "    # Calculate the accuracy by seeing how many of the predictions were correct\n",
    "    accuracy = sum([predictions[i].argmax() == labels[i] for i in range(len(labels))]) / len(labels)\n",
    "\n",
    "    # Show the first 20 images and their corresponding predictions\n",
    "    plt.figure(figsize=(10,10)) # Make is larger (10x10 inches) so you can see the pixels better\n",
    "    for i in range(20):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(images[i], cmap='gray_r')                    # Show the images in reverse grayscale (black on white)\n",
    "        plt.xlabel(f\"Prediction: {predictions[i].argmax()}\")    # Show the label underneath the image\n",
    "    plt.suptitle(f\"Model accuracy: {accuracy:.2%} of {images.shape[0]} images\\nModel predictions for the first 20 images:\")\n",
    "    plt.show()\n",
    "\n",
    "show_predictions(train_images, train_labels, neural_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow - that was stunningly bad. Why do you think that is?\n",
    "\n",
    "Well, the model is initialized with random weights for the neural connections, so it's predictions are just random guesses. So it will typically have about 10% accuracy (because there are 10 digits, there is a 1 in 10 chance that a random guess will be the right answer). Try running the cell multiple times and you will see it's accuracy will be different each time, but typically in the 5%-15% range.\n",
    "\n",
    "To make the model work better, we first need to train it. Let's see how that works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First print out a summary of all the weights (aka 'parameters') in the neural network that are going to be trained\n",
    "print (neural_net.summary())    # You will see there are about 13,000 parameters in this neural network\n",
    "\n",
    "# Next, train the neural network on the training data (epochs=1 means it will go through the training data once)\n",
    "neural_net.fit(train_images, train_labels, epochs=1)\n",
    "\n",
    "# Now let's see how good it is at predictions on the data it was trained on:\n",
    "show_predictions(train_images, train_labels, neural_net)\n",
    "\n",
    "# Let's also see how good it is at predicitons on the test data set, which it has never seen before and was not trained on\n",
    "test_images, test_labels = test\n",
    "test_images = test_images / 255.0\n",
    "show_predictions(test_images, test_labels, neural_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's much better - we're now around 92% accuracy on both the training images and test images!\n",
    "\n",
    "In general, the \"test\" accuracy is what you care about, since it is predicting on images it has not seen before. If your neural net has much higher training accuracy than test accuracy, it means it is \"overfitting\" to the training data - a very common thing but it's not happening here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You try it\n",
    "\n",
    "Try to optimize the neural net so it's accuracy is over 97%. Modify the TODO's below to try combinations of:\n",
    "* **Longer training** - increase the EPOCHS (aka, the number of passes are done on the training data)\n",
    "* **A wider network** - increase the number of neurons in the hidden layer from 16 (e.g., try 32, 64, 128))\n",
    "* **A deeper network** - add another hidden layer\n",
    "\n",
    "\n",
    "Run things with different combinations and see what gives you the best results.\n",
    "\n",
    "Prepare to discuss afterwards: which optimizations were the most important for this application?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=1    # TODO - try different values for the epochs\n",
    "\n",
    "# Try creating a more complex network, deeper (more layers), wider (more neurons in the hidden layers),\n",
    "# or adding 'dropout' layers to prevent overfitting the training data, which will improve test accuracy\n",
    "neural_net = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),      # Input layer\n",
    "    # TODO - modify the layers below this line\n",
    "    tf.keras.layers.Dense(16, activation='relu'),       # Hidden layer(s)\n",
    "    # TODO - end of modifications\n",
    "    tf.keras.layers.Dense(10, activation='softmax')     # Output layer\n",
    "], name='more_complex_neural_net')\n",
    "neural_net.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) # TODO - try the 'adam' optimizer\n",
    "\n",
    "# First print out a summary of all the weights in ther neural network that are going to be trained\n",
    "print (neural_net.summary())\n",
    "\n",
    "# Train the network longer (more epochs)\n",
    "history = neural_net.fit(train_images, train_labels, epochs=EPOCHS)\n",
    "\n",
    "# Let's see if that improves the test accuracy\n",
    "show_predictions(test_images, test_labels, neural_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To learn more\n",
    "If you want to learn more about how to create neural nets, here are some resouces:\n",
    "* [**Kaggle learn**](https://www.kaggle.com/learn): Kaggle is a great resource for learning data science, which includes community, competitions, and short self-paced classes, and it's all free. A good sequence of their classes; into to Python (if you don't know the basics), intro to machine learning (basic concepts for all machine learning techniques), intro to deep learning (neural nets). Computer vision is a quick dive into neural nets specifically built for vision tasks (called convolution neural nets)\n",
    "* [**Andrew Ng's Machine Learning coursera class**](https://www.coursera.org/specializations/machine-learning-introduction): A great introduction to the various machine learning techniques (besides neural nets) that have been around for a long time.\n",
    "* [**Andrew Ng's Deep learning specialization**](https://www.coursera.org/specializations/deep-learning): A series of more advanced classes that will show you how to build neural nets for vision problems (CNN's, like facial recognition) and sequential models (LLM's, like ChatGPT). \"Deep learning\" is just another term for neural nets that have many layers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
